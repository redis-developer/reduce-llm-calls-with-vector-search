{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Semantic Caching\n",
    "\n",
    "Semantic caching is an intelligent caching strategy that stores and retrieves responses based on the meaning of queries rather than exact text matches. Unlike traditional caching that requires identical strings, semantic caching can return cached responses for questions that are semantically similar, even when phrased differently.\n",
    "\n",
    "## Semantic Caching vs. Traditional Caching vs. LLM Re-generation\n",
    "\n",
    "**Traditional caching** stores responses using exact query strings as keys:\n",
    "- **Fast retrieval** for identical queries\n",
    "- **Cache misses** for any variation in phrasing, even minor differences\n",
    "- **Low cache hit rates** in conversational applications where users rarely phrase questions identically\n",
    "\n",
    "**LLM re-generation** involves calling the language model for every query:\n",
    "- **Flexible** handling of any question variation\n",
    "- **High API costs** and latency for repeated similar questions\n",
    "\n",
    "**Semantic caching** uses vector similarity to match queries with cached responses:\n",
    "- **High cache hit rates** by matching semantically similar questions\n",
    "- **Cost reduction** by avoiding redundant LLM calls for similar queries\n",
    "- **Fast retrieval** through vector similarity search\n",
    "\n",
    "In this notebook, we'll implement semantic caching using RedisVL with pre-generated FAQs about a Chevrolet Colorado vehicle brochure, demonstrating how semantic similarity can dramatically improve cache hit rates compared to exact string matching."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Installing Dependencies\n",
    "\n",
    "This semantic caching implementation requires several Python libraries that work together to provide vector embeddings, caching functionality, and LLM integration.\n",
    "\n",
    "- RedisVL - Provides the semantic caching functionality built on top of Redis. This library handles vector storage, similarity search, and the caching interface we'll use to store and retrieve semantically similar queries."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T18:01:14.123426Z",
     "start_time": "2025-10-14T18:01:12.974234Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@file:DependsOn(\"com.redis:redisvl:0.0.1\")\n",
    "%use serialization"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Loading Pre-Generated FAQs\n",
    "\n",
    "For this semantic caching demonstration, we'll use pre-generated frequently asked questions (FAQs) about a Chevrolet Colorado vehicle brochure. These FAQs were created by processing the vehicle documentation and extracting question-answer pairs using an LLM.\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T18:01:20.627633Z",
     "start_time": "2025-10-14T18:01:20.582900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import java.io.File\n",
    "\n",
    "val jsonText = File(\"../data/3_colorado_faqs.json\").readText(Charsets.UTF_8)\n",
    "val jsonArray = Json.parseToJsonElement(jsonText).jsonArray\n",
    "\n",
    "println(\"Loaded ${jsonArray.size} FAQs from file\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 346 FAQs from file\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Setting up the Text Vectorizer\n",
    "\n",
    "The vectorizer is responsible for converting text into numerical vector representations that capture semantic meaning. RedisVL provides several vectorizer options such as OpenAI and VertexAI. We're using the HuggingFace Text Vectorizer for this example."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T18:01:22.703425Z",
     "start_time": "2025-10-14T18:01:22.568178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import com.redis.vl.utils.vectorize.SentenceTransformersVectorizer\n",
    "\n",
    "val vectorizer = SentenceTransformersVectorizer(\"Xenova/all-MiniLM-L6-v2\")\n",
    "\n",
    "val embedding = vectorizer.embed(\"What is the capital city of Italy?\")\n",
    "\n",
    "println(embedding.joinToString())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.009056281, 0.09096523, -0.051762886, 0.08848378, -0.12719342, -0.0703391, 0.029510844, 0.013291523, -0.057980966, -0.014017097, 0.03739981, -0.13108169, 0.0018671635, 0.03550265, -0.055068597, -0.04273072, 0.0480743, 0.035149302, 0.051385034, 0.008154835, 0.02939507, -0.02790439, 0.04798433, 0.012633902, 0.050369605, 0.03730664, -0.016114296, 0.016826835, -0.05483934, -0.04307148, -0.014681098, 0.0032649112, 0.10389013, -0.085853584, 0.016533818, 0.017277544, -0.012875621, -0.008417194, 0.106101766, -3.3647308E-4, 0.03838455, -0.007070606, 0.064803414, 0.04349774, 0.027908528, -0.004982669, 0.05417708, 0.08491659, 0.01753072, -0.04387867, -0.0089426385, -0.029429087, -0.04308129, -0.0137046715, -0.049384452, 0.079110876, 0.0159977, -0.023842642, 0.010396142, -0.017871607, -0.02013254, -0.029775942, -0.057334274, 0.079562895, 0.017678022, 0.046195857, -0.025770709, -0.052720636, -0.07104178, -0.016904766, 0.005821192, -0.04959368, 0.012194841, -0.06851538, 0.024740597, -0.06589627, -0.004739907, 0.019979797, 0.012046297, 0.025945937, 0.04738658, -0.026207888, -0.024006084, 0.06688492, 0.027395409, 0.0511346, 0.033016067, 0.012410808, -7.134781E-4, -0.0053796326, 0.024619037, 0.10826674, -0.029768111, -0.008205869, -0.034382585, 0.023230458, -0.023033625, 0.06288932, -0.05734033, 0.07995538, 0.020887373, -0.048439715, 0.06801826, 0.03367503, -0.03210259, 0.030324435, 0.07029199, -0.035357255, -0.0437311, -0.026227256, -0.117252186, -0.0637143, -0.025789985, -0.076391436, 0.021659859, 0.07295666, 0.079506256, 0.030736178, -0.018580705, 0.032889977, -0.027822956, -0.056768946, -0.017266978, -0.0187513, -0.052855123, 0.0026798288, -0.09833044, -4.265337E-33, -0.04522934, -0.038603127, 0.006782485, 0.056442842, -0.047985323, 0.056943357, 0.005727432, -0.07347524, -0.06966861, -0.06284734, 6.824111E-4, -0.13293485, -0.0028802142, -0.011797879, 0.091532454, 0.039949197, 0.044991918, 0.047134932, -0.038595345, -0.050638054, 0.013533677, 0.0056156493, -0.00128937, -0.10107974, -0.0062624826, -0.006572015, -0.01721928, 0.012505045, 0.016358247, 0.027294295, 0.014827963, 0.11129013, -0.012927993, -0.026968583, 0.011228542, 0.099366866, -0.025637725, -0.017972834, -0.006258892, 0.06267472, -0.046503223, 0.023930388, -0.04911905, 0.018191079, 0.056508224, -0.034028705, -0.058674965, -0.026060073, 0.10192595, -0.07542723, 0.029558491, -0.0063548926, -0.043660775, 0.013796782, 0.05591109, 0.13179655, 0.0014945822, 0.073946476, -0.00362497, 0.09263236, -0.008254736, 0.058894735, 0.028806994, 0.041127626, 0.050720066, 0.106417455, 0.04963482, 0.07839, 0.062062256, 0.041708015, 9.6040964E-4, -0.05741613, 0.029530406, 0.10063947, -0.039977487, 0.045762528, -0.01707651, -0.048533317, -0.026703384, 0.0071982993, -0.041772787, -0.052366402, -0.036398213, 0.04329747, 0.047366947, -0.0023107647, 0.001604334, -0.02657378, -0.0017699071, -0.033968117, -0.059102736, -0.057025284, -0.058409713, 0.009664118, -0.008185311, 2.1191983E-33, 0.02503501, -0.05893375, -0.054135744, -0.013791176, -0.16847505, -0.056284852, -0.013744822, -0.0122961225, 0.0031321992, 0.053306993, -0.072457984, -0.0476266, 0.010839893, -0.03926069, 0.027747422, 0.10246861, 0.091257475, -0.015415793, -0.068407044, -0.10341207, -0.08215669, -0.03483035, -0.102931306, -0.07483412, -0.056837633, -0.027723843, -0.07740979, -0.014597713, 0.0067502027, -0.039716292, -0.04219018, -0.036527764, -0.058196455, -0.019601742, -0.032604992, 0.10461292, 0.0416616, -0.0481787, 0.091960885, 0.049276114, -0.0652168, -0.020950038, 0.07045577, 0.12440737, 0.07806728, 0.0073797563, 0.039370913, 0.002310497, -0.045826662, -0.006844643, 0.032626607, -0.039485242, -0.038203005, 0.010807971, 0.024200222, 0.017911695, -0.009244083, 0.034157734, -0.06378024, -0.09688441, 0.0928941, 0.020900233, -0.041648738, 0.062452674, 0.010918287, 0.044152, -0.08620699, 0.019485684, 0.013766632, -0.011806223, 0.059487995, 8.969072E-4, -0.08984199, 0.045840707, -0.08102404, 0.09381022, 0.049054053, 0.07864653, 0.055541668, -0.059208665, -0.0028986053, -0.0077899722, -0.04229291, 0.014191566, -0.052229255, -0.013464374, 0.08817786, -0.026562197, 0.06472866, 0.0073218145, -0.031644728, 0.065533295, 0.039485324, -0.0784605, 0.0044285893, -1.8748269E-8, 0.012146794, 0.020252327, -0.04066794, 0.0826934, 0.013210786, 0.011821769, 0.04016033, -0.027048599, 0.015920155, 0.01708129, -0.081510864, -0.0075302, -0.041846845, -0.061824482, -0.052197114, 0.04438127, 0.036889043, 0.029691536, 0.022707561, -0.007839727, 0.023343714, 0.0074147084, -0.081928894, -0.00935852, -0.024256242, -0.08159295, 0.0391832, 0.07591707, -0.04517342, 0.0011093953, 0.05846702, -0.07561812, -0.012565128, -0.08454925, -0.043759752, 0.07977247, -0.0046581454, -0.08857544, -0.012337672, -0.033817444, 0.022975812, -0.013439647, 0.05287376, 8.4293383E-4, 0.046390817, 0.015289715, 0.0053871227, -0.008255393, 0.0038129103, -0.078331016, -0.0831567, 0.020810202, 0.061217535, 0.033761967, 0.06302245, 0.0040639304, 0.062217683, 0.058209386, 0.046823863, 0.063531056, 0.04160275, -0.021602299, 0.029407658, -0.011543353\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Creating the SemanticCache\n"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T18:01:24.750387Z",
     "start_time": "2025-10-14T18:01:24.707649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import com.redis.vl.extensions.cache.SemanticCache\n",
    "import redis.clients.jedis.UnifiedJedis\n",
    "\n",
    "val jedis = UnifiedJedis()\n",
    "\n",
    "// Initialize the semantic cache with Redis connection\n",
    "val cache = SemanticCache.Builder()\n",
    "    .name(\"llmcache\")\n",
    "    .distanceThreshold(0.2F)\n",
    "    .ttl(360)\n",
    "    .redisClient(jedis)\n",
    "    .vectorizer(vectorizer)\n",
    "    .build()"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Storing FAQs in the Semantic Cache"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T18:01:29.975705Z",
     "start_time": "2025-10-14T18:01:26.362033Z"
    }
   },
   "cell_type": "code",
   "source": [
    "jsonArray.forEachIndexed { i, el ->\n",
    "    val obj = el.jsonObject\n",
    "    val prompt = obj[\"prompt\"]?.jsonPrimitive?.content.orEmpty()\n",
    "    val response = obj[\"response\"]?.jsonPrimitive?.content.orEmpty()\n",
    "    cache.store(prompt, response)\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Testing the Semantic Cache"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T18:01:31.434052Z",
     "start_time": "2025-10-14T18:01:31.364841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val cacheHit = cache.check(\"What models of chevy colorado are available?\").get()\n",
    "println(\"Prompt: ${cacheHit.prompt}\")\n",
    "println(\"Response: ${cacheHit.response}\")\n",
    "println(\"Distance: ${cacheHit.distance}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: What are the available models of the Colorado?\n",
      "Response: The available models of the Colorado are WT, LT, Z71, and ZR2.\n",
      "Distance: 0.17270815\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T18:01:32.845541Z",
     "start_time": "2025-10-14T18:01:32.794615Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val cacheHit = cache.check(\"What entertainment system comes with the car?\").get()\n",
    "println(\"Prompt: ${cacheHit.prompt}\")\n",
    "println(\"Response: ${cacheHit.response}\")\n",
    "println(\"Distance: ${cacheHit.distance}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: What entertainment system is included in the vehicle?\n",
      "Response: The vehicle includes the Chevrolet Infotainment 3 system with an 8-inch diagonal color touch-screen.\n",
      "Distance: 0.09986466\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T18:01:34.206944Z",
     "start_time": "2025-10-14T18:01:34.164503Z"
    }
   },
   "cell_type": "code",
   "source": "cache.check(\"Does the car drive on the water?\")",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Optional.empty"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "name": "kotlin",
   "version": "2.2.20-dev-4982",
   "mimetype": "text/x-kotlin",
   "file_extension": ".kt",
   "pygments_lexer": "kotlin",
   "codemirror_mode": "text/x-kotlin",
   "nbconvert_exporter": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
